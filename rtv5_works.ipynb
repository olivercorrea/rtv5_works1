{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5 BI\n",
        "\n",
        "> Agregar bloque entrecomillado\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z1xfie9jdxTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ztSuzDD2b-F",
        "outputId": "ec77e32c-e15e-4e41-afb8-610a5fcea727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bytewax==0.13.1\n",
            "  Downloading bytewax-0.13.1-cp310-cp310-manylinux_2_31_x86_64.whl.metadata (12 kB)\n",
            "Collecting river\n",
            "  Downloading river-0.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Collecting geopy==2.2.0\n",
            "  Downloading geopy-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting requests==2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting multiprocess>=0.70 (from bytewax==0.13.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting dill>=0.3.5 (from bytewax==0.13.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting geographiclib<2,>=1.49 (from geopy==2.2.0)\n",
            "  Downloading geographiclib-1.52-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting charset-normalizer<3,>=2 (from requests==2.28.1)\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.1) (3.10)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests==2.28.1)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.1) (2024.8.30)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from river) (1.26.4)\n",
            "Requirement already satisfied: pandas<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from river) (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=2.1->river) (1.16.0)\n",
            "Downloading bytewax-0.13.1-cp310-cp310-manylinux_2_31_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geopy-2.2.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading river-0.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geographiclib-1.52-py3-none-any.whl (38 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python, geographiclib, urllib3, geopy, dill, charset-normalizer, requests, multiprocess, river, bytewax\n",
            "  Attempting uninstall: geographiclib\n",
            "    Found existing installation: geographiclib 2.0\n",
            "    Uninstalling geographiclib-2.0:\n",
            "      Successfully uninstalled geographiclib-2.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: geopy\n",
            "    Found existing installation: geopy 2.4.1\n",
            "    Uninstalling geopy-2.4.1:\n",
            "      Successfully uninstalled geopy-2.4.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.1 which is incompatible.\n",
            "yfinance 0.2.43 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bytewax-0.13.1 charset-normalizer-2.1.1 dill-0.3.8 geographiclib-1.52 geopy-2.2.0 kafka-python-2.0.2 multiprocess-0.70.16 requests-2.28.1 river-0.21.2 urllib3-1.26.20\n"
          ]
        }
      ],
      "source": [
        "!pip install bytewax==0.13.1 river scipy geopy==2.2.0 requests==2.28.1 kafka-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos Redpanda"
      ],
      "metadata": {
        "id": "1sMbEcHa2pVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -1sLf 'https://packages.vectorized.io/nzc4ZYQK3WRGd9sy/redpanda/cfg/setup/bash.deb.sh' | sudo -E bash\n",
        "!sudo apt install redpanda -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS81CIe42oLI",
        "outputId": "fd71723c-5c1d-4c4e-ceb3-5ddee9ccaeb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing the  setup script for the 'redpanda/redpanda' repository ...\n",
            "\n",
            "\u001b[1K\r\u001b[32m  RUN\u001b[39;49m: Checking for required executable 'curl' ...\u001b[1K\r\u001b[1K\r\u001b[32m   OK\u001b[39;49m: Checking for required executable 'curl' ...\n",
            "\u001b[1K\r\u001b[32m  RUN\u001b[39;49m: Checking for required executable 'apt-get' ...\u001b[1K\r\u001b[1K\r\u001b[32m   OK\u001b[39;49m: Checking for required executable 'apt-get' ...\n",
            "\u001b[1K\r\u001b[32m  RUN\u001b[39;49m: \u001b[1K\r\u001b[1K\r\u001b[32m   OK\u001b[39;49m: Detecting your OS distribution and release using system methods ...\n",
            " ^^^^: ... Detected/provided for your OS/distribution, version and architecture:\n",
            " >>>>:\n",
            " >>>>: ... distro=\u001b[32mubuntu\u001b[39;49m  version=\u001b[32m22.04\u001b[39;49m  codename=\u001b[32mjammy\u001b[39;49m  arch=\u001b[32mx86_64\u001b[39;49m  \n",
            " >>>>:\n",
            "\u001b[41;97m NOPE\u001b[39;49m: Checking for apt dependency 'apt-transport-https' ...\n",
            "\u001b[32m   OK\u001b[39;49m: Updating apt repository metadata cache ...\n",
            "\u001b[32m   OK\u001b[39;49m: Attempting to install 'apt-transport-https' ...\n",
            "\u001b[32m   OK\u001b[39;49m: Checking for apt dependency 'ca-certificates' ...\n",
            "\u001b[32m   OK\u001b[39;49m: Checking for apt dependency 'gnupg' ...\n",
            "\u001b[32m   OK\u001b[39;49m: Checking for apt signed-by key support ...\n",
            "\u001b[32m   OK\u001b[39;49m: Importing 'redpanda/redpanda' repository GPG keys ...\n",
            "\u001b[32m   OK\u001b[39;49m: Checking if upstream install config is OK ...\n",
            "\u001b[32m   OK\u001b[39;49m: Installing 'redpanda/redpanda' repository via apt ...\n",
            "\u001b[32m   OK\u001b[39;49m: Updating apt repository metadata cache ...\n",
            "\u001b[32m   OK\u001b[39;49m: The repository has been installed successfully - You're ready to rock!\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  redpanda-rpk redpanda-tuner\n",
            "The following NEW packages will be installed:\n",
            "  redpanda redpanda-rpk redpanda-tuner\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 55.5 MB of archives.\n",
            "After this operation, 277 MB of additional disk space will be used.\n",
            "Get:1 https://dl.redpanda.com/public/redpanda/deb/ubuntu jammy/main amd64 redpanda-rpk amd64 24.2.5-1 [13.5 MB]\n",
            "Get:2 https://dl.redpanda.com/public/redpanda/deb/ubuntu jammy/main amd64 redpanda-tuner amd64 24.2.5-1 [2,844 B]\n",
            "Get:3 https://dl.redpanda.com/public/redpanda/deb/ubuntu jammy/main amd64 redpanda amd64 24.2.5-1 [42.0 MB]\n",
            "Fetched 55.5 MB in 4s (14.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package redpanda-rpk.\n",
            "(Reading database ... 123609 files and directories currently installed.)\n",
            "Preparing to unpack .../redpanda-rpk_24.2.5-1_amd64.deb ...\n",
            "Unpacking redpanda-rpk (24.2.5-1) ...\n",
            "Selecting previously unselected package redpanda-tuner.\n",
            "Preparing to unpack .../redpanda-tuner_24.2.5-1_amd64.deb ...\n",
            "Unpacking redpanda-tuner (24.2.5-1) ...\n",
            "Selecting previously unselected package redpanda.\n",
            "Preparing to unpack .../redpanda_24.2.5-1_amd64.deb ...\n",
            "Unpacking redpanda (24.2.5-1) ...\n",
            "Setting up redpanda-rpk (24.2.5-1) ...\n",
            "Setting up redpanda-tuner (24.2.5-1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redpanda-tuner.service → /lib/systemd/system/redpanda-tuner.service.\n",
            "Setting up redpanda (24.2.5-1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redpanda.service → /lib/systemd/system/redpanda.service.\n",
            "\n",
            "To get the most out of the fastest queue in the west, enable production mode by\n",
            "running the following:\n",
            "\n",
            "    sudo rpk redpanda mode production\n",
            "\n",
            "followed by:\n",
            "\n",
            "    sudo rpk redpanda tune all\n",
            "    sudo systemctl start redpanda\n",
            "\n",
            "This will autotune your system to give you the best performance from Redpanda.\n",
            "You can get more information on the tuning parameters here:\n",
            "https://docs.redpanda.com/docs/introduction/autotune/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniciamos Redpana"
      ],
      "metadata": {
        "id": "NXAge-lr2zgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "IqkwHOfm3CRI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "env = os.environ.copy()\n",
        "p = subprocess.Popen('sudo rpk redpanda start', shell=True, env=env)"
      ],
      "metadata": {
        "id": "TtRtYdCX3Dxq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rpk redpanda admin brokers list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixQftMwX3JFi",
        "outputId": "7591d16c-23df-48ad-8f60-271859cf9dc6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NODE-ID  NUM-CORES  MEMBERSHIP-STATUS  IS-ALIVE  BROKER-VERSION\n",
            "0        2          active             true      v24.2.5 - f65c3be191418e914a298a2df97bdb7f279855be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos lo necesario"
      ],
      "metadata": {
        "id": "B_Fr01QP3SjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from kafka import KafkaProducer, KafkaAdminClient\n",
        "from kafka.admin import NewTopic\n",
        "from geopy.geocoders import Nominatim\n",
        "from river import anomaly\n",
        "from scipy import stats\n",
        "import subprocess\n",
        "import bytewax.dataflow as flow\n",
        "from bytewax.inputs import ManualInputConfig\n",
        "from bytewax.outputs import KafkaOutputConfig, StdOutputConfig\n",
        "from bytewax.execution import run_main\n",
        "from bytewax.window import TumblingWindowConfig, EventClockConfig"
      ],
      "metadata": {
        "id": "x5s4lB3y3WQN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gohQZWKG7kXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_kafka():\n",
        "    admin_client = KafkaAdminClient(bootstrap_servers=['localhost:9092'])\n",
        "    topic = NewTopic(name='traffic_data', num_partitions=1, replication_factor=1)\n",
        "    try:\n",
        "        admin_client.create_topics([topic])\n",
        "        print(\"Topic 'traffic_data' creado exitosamente.\")\n",
        "    except TopicAlreadyExistsError:\n",
        "        print(\"El topic 'traffic_data' ya existe. Continuando con el procesamiento.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al crear el topic: {e}\")"
      ],
      "metadata": {
        "id": "kav0tfNS3a1U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_traffic_data(location):\n",
        "    return f'Tráfico en {location}: {50 + hash(location) % 50} vehículos/min'"
      ],
      "metadata": {
        "id": "sf9ERNKA3eTK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_traffic_data(data):\n",
        "    match = re.search(r'(\\d+) vehículos/min', data)\n",
        "    return int(match.group(1)) if match else 0"
      ],
      "metadata": {
        "id": "NoF5maMC3hN6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def geolocate(location):\n",
        "    geolocator = Nominatim(user_agent=\"traffic_monitor\")\n",
        "    return geolocator.geocode(location)"
      ],
      "metadata": {
        "id": "CouCTDY03jOi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_anomaly(data):\n",
        "    detector = anomaly.HalfSpaceTrees(\n",
        "        n_trees=10,\n",
        "        height=8,\n",
        "        window_size=256,\n",
        "        seed=42\n",
        "    )\n",
        "    is_anomaly = detector.score_one({'value': data}) > 0.95\n",
        "    detector = detector.learn_one({'value': data})\n",
        "    return is_anomaly"
      ],
      "metadata": {
        "id": "cDMJuZxh3lNU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_variation(data):\n",
        "    return stats.variation(data)"
      ],
      "metadata": {
        "id": "7BYSwyvz3nhg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_traffic_data(data):\n",
        "    if isinstance(data, tuple) and len(data) == 2:\n",
        "        location, traffic = data\n",
        "    elif isinstance(data, str):\n",
        "        location, traffic = data.split(\":\")[0].split(\"en \")[-1].strip(), data\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected data format: {data}\")\n",
        "\n",
        "    geo = geolocate(location)\n",
        "    traffic_value = parse_traffic_data(traffic)\n",
        "    is_anomaly = detect_anomaly(traffic_value)\n",
        "    return {\n",
        "        'location': location,\n",
        "        'coords': (geo.latitude, geo.longitude) if geo else None,\n",
        "        'traffic': traffic_value,\n",
        "        'is_anomaly': is_anomaly\n",
        "    }"
      ],
      "metadata": {
        "id": "fzQQZF803q7g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_builder(worker_index, worker_count, resume_state):\n",
        "    for data in input_data:\n",
        "        yield None, data\n"
      ],
      "metadata": {
        "id": "kF04Ju7eX24c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_flow():\n",
        "    flow_builder = flow.Dataflow()\n",
        "    flow_builder.input(\"input\", ManualInputConfig(input_builder))\n",
        "    flow_builder.map(lambda x: print(f\"Debug: received data {x}\") or x)\n",
        "    flow_builder.map(process_traffic_data)\n",
        "    flow_builder.capture(StdOutputConfig())\n",
        "    return flow_builder"
      ],
      "metadata": {
        "id": "i93ISgK03t_p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(locations):\n",
        "    setup_kafka()\n",
        "\n",
        "    global input_data\n",
        "    input_data = [get_traffic_data(location) for location in locations]\n",
        "\n",
        "    dataflow = build_flow()\n",
        "    run_main(dataflow)"
      ],
      "metadata": {
        "id": "WsTlWUQ231S8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso\n",
        "locations = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"]\n",
        "main(locations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0IJmgGr34ed",
        "outputId": "1a2deae1-378b-4210-c688-3c7d2276b2f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 'traffic_data' creado exitosamente.\n",
            "Debug: received data Tráfico en New York: 98 vehículos/min\n",
            "{'location': 'New York', 'coords': (40.7127281, -74.0060152), 'traffic': 98, 'is_anomaly': False}\n",
            "Debug: received data Tráfico en Los Angeles: 68 vehículos/min\n",
            "{'location': 'Los Angeles', 'coords': (34.0536909, -118.242766), 'traffic': 68, 'is_anomaly': False}\n",
            "Debug: received data Tráfico en Chicago: 94 vehículos/min\n",
            "{'location': 'Chicago', 'coords': (41.8755616, -87.6244212), 'traffic': 94, 'is_anomaly': False}\n",
            "Debug: received data Tráfico en Houston: 63 vehículos/min\n",
            "{'location': 'Houston', 'coords': (29.7589382, -95.3676974), 'traffic': 63, 'is_anomaly': False}\n",
            "Debug: received data Tráfico en Phoenix: 91 vehículos/min\n",
            "{'location': 'Phoenix', 'coords': (33.4484367, -112.074141), 'traffic': 91, 'is_anomaly': False}\n"
          ]
        }
      ]
    }
  ]
}